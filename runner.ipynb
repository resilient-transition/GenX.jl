{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Set up `GenX` Project in Current Folder\n",
    "\n",
    "This step assumes you've installed `julia` already but have not set up the current `GenX` project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!julia --project=. Install.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Export `GenX` Input CSVs from Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from upath import UPath\n",
    "from loguru import logger\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, backtrace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "- [x] Do the xlwings thing where the SharePoint path is updated in the spreadsheet -> used VBA UDF\n",
    "- [ ] Do we need something like `kit-ui connect`? I don't think so\n",
    "- [ ] File picker to connect to spreadsheet?\n",
    "- [x] Format this notebook before committing\n",
    "- [x] Copy Run.jl\n",
    "- [x] Copy settings\n",
    "- [ ] Check that demand_data, fuel_data, and generator_variability CSVs have the same length\n",
    "- [x] Save a mapping of the planning period to year, so that it can be read in by spreadsheet, or when concatenating the dataframe (instead of guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wb = xw.Book(\n",
    "    '/Users/roderick/Library/CloudStorage/OneDrive-SharedLibraries-ResilientTransition/5.001 Kentucky Resource Council - Documents/Data/Kentucky Load Resource Model.xlsb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_case(base_folder: UPath, case_subfolder: str | None = None):\n",
    "    global name, range, col\n",
    "    # Get CSV names as a nested dictionary (since some CSVs have been split into multiple separate tables\n",
    "    # Named ranges have the format of [csv file name]...[#]...[optional transformation, either .T or .ffill]\n",
    "    csv_names = defaultdict(list)\n",
    "    for name in wb.names:\n",
    "        if \".csv\" in name.name:\n",
    "            csv_names[name.name.split(\"...\")[0]].append(name)\n",
    "    for csv_name, ranges in csv_names.items():\n",
    "        dfs = []\n",
    "        for rng in ranges:\n",
    "            # Get each range as a dataframe\n",
    "            df = rng.refers_to_range.options(pd.DataFrame, index=0,\n",
    "                                               header=(1 if not rng.name.endswith(\"...T\") else 0)).value\n",
    "            df = df.dropna(how=\"all\", axis=1)\n",
    "            df = df.dropna(how=\"all\", axis=0)\n",
    "            if \"resource\" in df.columns:\n",
    "                df = df.dropna(subset=\"resource\", axis=0)\n",
    "            if \"drop\" in df.columns:\n",
    "                df = df[df[\"drop\"] != True]\n",
    "\n",
    "            # Apply optional transform\n",
    "            if rng.name.endswith(\"...T\"):\n",
    "                df = df.set_index(df.columns[0])\n",
    "                df = df.T\n",
    "            elif rng.name.endswith(\"...ffill\"):\n",
    "                df = df.ffill()\n",
    "            elif rng.name.endswith(\"...drop...1\"):\n",
    "                df = df.iloc[:, [0, -1]]\n",
    "                df = df.dropna(how=\"any\")\n",
    "            elif rng.name.endswith(\"...drop...3\"):\n",
    "                df = df.iloc[:, [0, -3, -2, -1]]\n",
    "                df = df.dropna(how=\"any\")\n",
    "\n",
    "            if csv_name in [\n",
    "                \"resources\\\\policy_assignments\\\\Resource_NQC_derate.csv\",\n",
    "                \"resources\\\\policy_assignments\\\\ELCC_multipliers.csv\",\n",
    "                \"resources\\\\Resource_multistage_data.csv\",\n",
    "            ]:\n",
    "                df = df.rename(columns={\"resource\": \"Resource\"})\n",
    "\n",
    "            # Change types for columns to int & strings\n",
    "            int_columns = [\n",
    "                col for col in df.columns if col in\n",
    "                 [\n",
    "                     \"can_retire\",\n",
    "                     \"zone\",\n",
    "                     \"new_build\",\n",
    "                     \"model\",\n",
    "                     \"lds\",\n",
    "                     \"Time_Index\"\n",
    "                 ]\n",
    "            ]\n",
    "            df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "            str_columns = [\n",
    "                col for col in df.columns if col in\n",
    "                 [\n",
    "                     \"cluster\",\n",
    "                     \"region\",\n",
    "                 ]\n",
    "            ]\n",
    "            df[str_columns] = df[str_columns].astype(str)\n",
    "\n",
    "            if df.isna().any().any():\n",
    "                logger.error(f\"{csv_name} has blank cells. GenX currently does not have consistent handling of missing data, so please fill in or add placeholder values.\")\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "        # Join all the dfs\n",
    "        final_df = pd.concat([df.reset_index(drop=True) for df in dfs], axis=1)\n",
    "\n",
    "        # Save joined dataframe to CSV\n",
    "        planning_period_folder = base_folder / case_subfolder if case_subfolder else base_folder\n",
    "        filepath = planning_period_folder / csv_name.replace(\"\\\\\", os.sep)\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        final_df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "base_folder = UPath(wb.names[\"BaseFolder\"].refers_to_range.value)\n",
    "case_name = wb.names[\"CaseName\"].refers_to_range.value\n",
    "\n",
    "if base_folder.exists():\n",
    "    logger.warning(f\"Overwriting case: {base_folder}\")\n",
    "base_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save mapping of planning periods to period IDs\n",
    "planning_periods = wb.sheets[\"GenX Settings\"].tables[\"ModeledYears\"].range.options(pd.DataFrame, index=1).value.dropna().index.astype(int).values\n",
    "\n",
    "# Save mapping of planning periods so that we know what years to map inputs_p1, etc. to\n",
    "wb.sheets[\"GenX Settings\"].tables[\"ModeledYears\"].range.options(pd.DataFrame, index=1).value.dropna().to_csv(base_folder / \"planning_periods.csv\", index=True)\n",
    "\n",
    "counter = 1\n",
    "for planning_period in planning_periods:\n",
    "    wb.sheets[\"GenX Settings\"].range(\"ActiveYear\").value = planning_period\n",
    "    wb.app.calculate()\n",
    "\n",
    "    logger.info(f\"Saving case inputs for {planning_period}: (inputs_p{counter})\")\n",
    "    save_case(base_folder=base_folder, case_subfolder=f\"inputs/inputs_p{counter}\")\n",
    "    counter += 1\n",
    "\n",
    "    # Save settings .yml files\n",
    "    wb.sheets[\"GenX Settings\"].range(\"settings\\genx_settings.yml\").options(pd.DataFrame).value\n",
    "\n",
    "# Settings\n",
    "logger.info(\"Saving settings...\")\n",
    "\n",
    "base_settings_folder = UPath(\"/Users/roderick/PycharmProjects/resilient-transition/GenX.jl/__base_settings__\")\n",
    "\n",
    "if (base_folder / \"settings\").exists():\n",
    "    shutil.rmtree(base_folder / \"settings\")\n",
    "shutil.copytree(base_settings_folder, base_folder / \"settings\")\n",
    "\n",
    "# TODO: Clean up how these settings files are parsed\n",
    "\n",
    "# genx_settings.yml\n",
    "wb.sheets[\"GenX Settings\"].range(r\"settings\\genx_settings.yml\").options(pd.Series, header=False).value.astype(int).reset_index().astype(str).agg(\"\".join, axis=1).to_csv(base_folder / \"settings\" / \"genx_settings.yml\", index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "# multi_stage_settings.yml\n",
    "wb.sheets[\"GenX Settings\"].range(r\"settings\\multi_stage_settings.yml\").options(pd.Series, header=False).value.apply(lambda x: int(x) if isinstance(x, (float, bool, int)) else x).reset_index().astype(str).agg(\"\".join, axis=1).to_csv(base_folder / \"settings\" / \"multi_stage_settings.yml\", index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "# time_domain_reduction_settings.yml\n",
    "wb.sheets[\"GenX Settings\"].range(r\"settings\\time_domain_reduction_settings.yml\").options(pd.Series, header=False).value.replace({None: \" \"}).apply(lambda x: int(x) if isinstance(x, (float, bool, int)) else x).reset_index().astype(str).agg(\"\".join, axis=1).replace({\"None\": \"\"}).to_csv(base_folder / \"settings\" / \"time_domain_reduction_settings.yml\", index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "# highs_settings.yml\n",
    "wb.sheets[\"GenX Settings\"].range(r\"settings\\highs_settings.yml\").options(pd.Series, header=False).value.replace({None: \" \"}).apply(lambda x: int(x) if isinstance(x, (bool, int)) else x).reset_index().astype(str).agg(\"\".join, axis=1).replace({\"None\": \"\"}).to_csv(base_folder / \"settings\" / \"highs_settings.yml\", index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "logger.success(f\"Saved multi-stage capacity expansion case: {case_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!julia --project=. Run.jl $base_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (base_folder / \"planning_periods.csv\").exists():\n",
    "    periods_range = pd.read_csv(base_folder / \"planning_periods.csv\", index_col=-1)[\"Planning Period\"].astype(\"int\").to_dict()\n",
    "    periods_range = {base_folder / \"results\" / f\"results_{k}\": v for k, v in periods_range.items()}\n",
    "else:\n",
    "    subfolders = sorted(list((base_folder / \"results\").glob(\"results_p*\")), key=lambda path: int(path.stem.split(\"results_p\")[-1]))\n",
    "    periods_range = {p: None for p in subfolders}\n",
    "\n",
    "# Total Capacity\n",
    "portfolio = pd.read_csv(base_folder / \"results\" / \"capacities_multi_stage.csv\", index_col=0)\n",
    "portfolio = portfolio[[col for col in portfolio.columns if not col.startswith(\"StartCap\")]]\n",
    "portfolio = portfolio.rename(columns={\"EndCap_p\"+ path.stem.split(\"results_p\")[-1]: period for path, period in periods_range.items()})\n",
    "portfolio = portfolio.drop([\"Zone\"], axis=1)\n",
    "wb.sheets[\"GenX Results\"].range(\"capacities_multi_stage\").clear_contents()\n",
    "wb.sheets[\"GenX Results\"].range(\"capacities_multi_stage\").value = portfolio\n",
    "\n",
    "# Builds\n",
    "def get_net_build(path):\n",
    "    df = pd.read_csv(path / \"capacity.csv\", index_col=0)[[\"NewCap\", \"RetCap\"]]\n",
    "    return df[\"NewCap\"] - df[\"RetCap\"]\n",
    "builds = pd.concat({period: get_net_build(path) for path, period in periods_range.items()}, axis=1)\n",
    "wb.sheets[\"GenX Results\"].range(\"capacities\").clear_contents()\n",
    "wb.sheets[\"GenX Results\"].range(\"capacities\").value = builds\n",
    "\n",
    "# CFs\n",
    "cfs = pd.concat({period: pd.read_csv(path / \"capacityfactor.csv\", index_col=0)[\"CapacityFactor\"] for path, period in periods_range.items()}, axis=1)\n",
    "wb.sheets[\"GenX Results\"].range(\"cfs\").clear_contents()\n",
    "wb.sheets[\"GenX Results\"].range(\"cfs\").value = cfs\n",
    "\n",
    "# Generation\n",
    "generation = (pd.concat({period: pd.read_csv(path / \"power.csv\", index_col=0).T[\"AnnualSum\"] for path, period in periods_range.items()}, axis=1) / 1e6).round(3)\n",
    "wb.sheets[\"GenX Results\"].range(\"generation\").clear_contents()\n",
    "wb.sheets[\"GenX Results\"].range(\"generation\").value = generation\n",
    "\n",
    "\n",
    "wb.sheets[\"GenX Results\"].activate()\n",
    "wb.app.calculate()\n",
    "print(f\"Loaded results at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# TDR Clustering Visualization\n",
    "\n",
    "- [ ] Plots\n",
    "- [ ] Are TDRs the same for every planning period? If not, how much are they changing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "axes = dict(\n",
    "    showgrid=False,\n",
    "    linecolor=\"rgb(120, 120, 120)\",\n",
    "    linewidth=1,\n",
    "    showline=True,\n",
    "    ticks=\"outside\",\n",
    "    tickcolor=\"rgb(120, 120, 120)\",\n",
    "    mirror=True,\n",
    ")\n",
    "\n",
    "pio.templates[\"e3\"] = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        font=dict(family=\"CommitMono\", size=11, color=\"rgb(120, 120, 120)\"),\n",
    "        title=dict(\n",
    "            font=dict(\n",
    "                # size=32,\n",
    "                color=\"rgb(3, 78, 110)\",\n",
    "            ),\n",
    "            x=0.05,\n",
    "            y=0.95,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"bottom\",\n",
    "        ),\n",
    "        xaxis=axes,\n",
    "        yaxis=axes,\n",
    "        margin=dict(t=60, b=100, r=60, l=60),\n",
    "    )\n",
    ")\n",
    "\n",
    "pio.templates[\"5.4x12.32\"] = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        height=5.4 * 144,\n",
    "        width=12.32 * 144,\n",
    "    )\n",
    ")\n",
    "\n",
    "pio.templates.default = \"e3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from upath import UPath\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "base_path = base_folder / \"inputs\" / \"inputs_p1\"\n",
    "timeseries_to_compare = {\n",
    "    \"Demand_data.csv\": [\n",
    "        (\"Demand_MW_z1\", \"rgba(54, 176, 72, 0.5)\")\n",
    "    ],\n",
    "    \"Generators_variability.csv\": [\n",
    "        (\"Solar:0\", \"rgba(255, 192, 0, 0.5)\"),\n",
    "        (\"Wind:0\", \"rgba(49, 235, 255, 0.5)\"),\n",
    "        (\"Wind - New Generic:0\", \"rgba(49, 235, 255, 0.5)\"),\n",
    "        (\"Wind - New Generic:1\", \"rgba(49, 235, 255, 0.5)\"),\n",
    "        (\"Wind - New Generic:2\", \"rgba(49, 235, 255, 0.5)\"),\n",
    "        (\"Wind - New Generic:3\", \"rgba(49, 235, 255, 0.5)\"),\n",
    "        (\"Solar - New Generic:0\", \"rgba(255, 192, 0, 0.5)\"),\n",
    "        (\"Solar - New Generic:1\", \"rgba(255, 192, 0, 0.5)\"),\n",
    "        (\"Solar - New Generic:2\", \"rgba(255, 192, 0, 0.5)\"),\n",
    "        (\"Solar - New Generic:3\", \"rgba(255, 192, 0, 0.5)\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "def tdr_plots(base_path: UPath, timeseries_to_compare: dict[str, list[str]]):\n",
    "    # Get TDR settings & period mapping\n",
    "    with open(base_path / \"TDR_results\" / \"time_domain_reduction_settings.yml\", \"r\") as f:\n",
    "        tdr_settings = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "    period_map = pd.read_csv(base_path / \"TDR_results\"/ \"Period_map.csv\", dtype=int)\n",
    "\n",
    "    with open(base_path / \"tdr_plots.html\", \"w\") as tdr_plots_file:\n",
    "        # Get timeseries to plot\n",
    "        for i, (csv_file, columns) in enumerate(timeseries_to_compare.items()):\n",
    "            for (column, color_str) in columns:\n",
    "                df = pd.read_csv(base_path / \"system\" / csv_file)[[\"Time_Index\", column]]\n",
    "\n",
    "                df[\"Period_Index\"] = ((df[\"Time_Index\"] - 1) // tdr_settings[\"TimestepsPerRepPeriod\"]) + 1\n",
    "                df[\"Hour\"] = (df[\"Time_Index\"]) - ((df[\"Period_Index\"] - 1) * 24)\n",
    "                df[\"Rep_Period\"] = df.merge(period_map, on=\"Period_Index\")[\"Rep_Period\"]\n",
    "\n",
    "                df = df.merge(\n",
    "                    df[[\"Period_Index\", \"Hour\", column]],\n",
    "                    left_on=[\"Rep_Period\", \"Hour\"],\n",
    "                    right_on=[\"Period_Index\", \"Hour\"],\n",
    "                    suffixes=[\"_original\", \"_sampled\"]\n",
    "                )[[f\"{column}_original\", f\"{column}_sampled\"]]\n",
    "                df.index = pd.Timestamp(\"1/1/2007\") + pd.to_timedelta(df.index, unit=\"h\")\n",
    "\n",
    "                # Plot\n",
    "                fig = make_subplots(rows=2, cols=1, subplot_titles=[\"Chronological\", \"Duration Curve\"], vertical_spacing=0.15)\n",
    "                fig.update_layout(title_text=f\"Time Domain Reduction Comparison:<br><b>{column}\", legend_tracegroupgap=180, width=1000, height=500)\n",
    "\n",
    "\n",
    "                # Chronological\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df.index,\n",
    "                        y=df[f\"{column}_original\"],\n",
    "                        name=\"Original\",\n",
    "                        legendgroup=1,\n",
    "                        line=dict(\n",
    "                            color=\"rgba(20, 20, 20, 0.5)\",\n",
    "                            width=1,\n",
    "                        ),\n",
    "                        ),\n",
    "                    row=1,\n",
    "                    col=1\n",
    "                )\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df.index,\n",
    "                        y=df[f\"{column}_sampled\"],\n",
    "                        name=\"Sampled\",\n",
    "                        legendgroup=1,\n",
    "                        line=dict(\n",
    "                            color=color_str,\n",
    "                            width=1,\n",
    "                        ),\n",
    "                        ),\n",
    "                    row=1,\n",
    "                    col=1\n",
    "                )\n",
    "\n",
    "                # Duration curve\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        y=df[f\"{column}_original\"].sort_values(ascending=False, ignore_index=True),\n",
    "                        name=\"Original\",\n",
    "                        legendgroup=2,\n",
    "                        line=dict(\n",
    "                            color=\"rgba(20, 20, 20, 0.5)\",\n",
    "                            width=1,\n",
    "                        ),\n",
    "                        ),\n",
    "                    row=2,\n",
    "                    col=1\n",
    "                )\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        y=df[f\"{column}_sampled\"].sort_values(ascending=False, ignore_index=True),\n",
    "                        name=\"Sampled\",\n",
    "                        legendgroup=2,\n",
    "                        line=dict(\n",
    "                            color=color_str,\n",
    "                            width=1,\n",
    "                        ),\n",
    "                        ),\n",
    "                    row=2,\n",
    "                    col=1\n",
    "                )\n",
    "                fig.show()\n",
    "                tdr_plots_file.write(fig.to_html(full_html=False, include_plotlyjs=\"cdn\" if i == 0 else None))\n",
    "\n",
    "tdr_plots(base_path, timeseries_to_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
