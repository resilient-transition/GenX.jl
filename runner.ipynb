{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T23:44:27.463371Z",
     "start_time": "2025-04-22T23:44:27.413025Z"
    }
   },
   "source": [
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "from pydeck.io.html import in_google_colab\n",
    "from upath import UPath"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Do the xlwings thing where the SharePoint path is updated\n",
    "# Format this notebook before committing\n",
    "# Copy Run.jl\n",
    "# Copy settings\n",
    "# Check that demand_data, fuel_data, and generator_variability CSVs have the same length"
   ],
   "id": "d39bb1e7c4e05aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T23:16:17.057488Z",
     "start_time": "2025-04-22T23:16:05.865955Z"
    }
   },
   "cell_type": "code",
   "source": "wb = xw.Book('/Users/roderick/Library/CloudStorage/OneDrive-SharedLibraries-ResilientTransition/5.001 Kentucky Resource Council - Documents/Data/Kentucky Load Resource Model.xlsb')",
   "id": "190d971ce51e9139",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:58:08.882Z",
     "start_time": "2025-04-23T18:58:06.389182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "base_folder = UPath(wb.names[\"BaseFolder\"].refers_to_range.value)\n",
    "\n",
    "# Get CSV names as a nested dictionary (since some CSVs have been split into multiple separate tables\n",
    "# Named ranges have the format of [csv file name]...[#]...[optional transformation, either .T or .ffill]\n",
    "csv_names = defaultdict(list)\n",
    "for name in wb.names:\n",
    "    if \".csv\" in name.name:\n",
    "        csv_names[name.name.split(\"...\")[0]].append(name)\n",
    "\n",
    "for csv_name, ranges in csv_names.items():\n",
    "    dfs = []\n",
    "    for range in ranges:\n",
    "        # Get each range as a dataframe\n",
    "        df = range.refers_to_range.options(pd.DataFrame, index=0, header=(1 if not range.name.endswith(\"...T\") else 0)).value\n",
    "        df = df.dropna(how=\"all\", axis=1)\n",
    "        df = df.dropna(how=\"all\", axis=0)\n",
    "        if \"resource\" in df.columns:\n",
    "            df = df.dropna(subset=\"resource\", axis=0)\n",
    "        if \"drop\" in df.columns:\n",
    "            df = df[df[\"drop\"] != True]\n",
    "\n",
    "        # Apply optional transform\n",
    "        if range.name.endswith(\"...T\"):\n",
    "            df = df.set_index(df.columns[0])\n",
    "            df = df.T\n",
    "        elif range.name.endswith(\"...ffill\"):\n",
    "            df = df.ffill()\n",
    "        elif range.name.endswith(\"...drop...1\"):\n",
    "            df = df.iloc[:, [0, -1]]\n",
    "            df = df.dropna(how=\"any\")\n",
    "        elif range.name.endswith(\"...drop...3\"):\n",
    "            df = df.iloc[:, [0, -3, -2, -1]]\n",
    "            df = df.dropna(how=\"any\")\n",
    "\n",
    "        if csv_name in [\n",
    "            \"resources\\\\policy_assignments\\\\Resource_NQC_derate.csv\",\n",
    "            \"resources\\\\policy_assignments\\\\ELCC_multipliers.csv\"\n",
    "        ]:\n",
    "            df = df.rename(columns={\"resource\": \"Resource\"})\n",
    "\n",
    "        # Change types for columns to int\n",
    "        int_columns = [\n",
    "            col for col in df.columns if col in\n",
    "            [\n",
    "                \"can_retire\",\n",
    "                \"new_build\",\n",
    "                \"model\",\n",
    "                \"lds\",\n",
    "                \"Time_Index\"\n",
    "            ]\n",
    "        ]\n",
    "        df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Join all the dfs\n",
    "    final_df = pd.concat([df.reset_index(drop=True) for df in dfs], axis=1)\n",
    "\n",
    "    # Save joined dataframe to CSV\n",
    "    filepath = base_folder / csv_name.replace(\"\\\\\", os.sep)\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    final_df.to_csv(filepath, index=False)"
   ],
   "id": "bf0353f75240050c",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:46:54.180678Z",
     "start_time": "2025-04-23T18:46:54.178582Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a9f5ad762369f340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7c70fc14a141b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
